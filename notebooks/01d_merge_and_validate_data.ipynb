{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# Configuration\n",
        "VALIDATION_CONFIG = {\n",
        "    'min_trading_days': 1000,  # Minimum number of trading days required\n",
        "    'max_missing_pct': 5,      # Maximum percentage of missing data allowed\n",
        "    'min_stock_sector_corr': 0.3  # Minimum correlation between stock and sector\n",
        "}\n",
        "\n",
        "# Required columns for validation\n",
        "REQUIRED_COLUMNS = {\n",
        "    'stocks': ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Sector'],\n",
        "    'sectors': ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
        "}\n",
        "\n",
        "# Define GICS sectors and their ETFs\n",
        "SECTOR_ETF_MAP = {\n",
        "    'XLK': 'Information Technology',    # Technology sector benchmark\n",
        "    'XLF': 'Financials',               # Banks, Insurance, Investment firms\n",
        "    'XLV': 'Healthcare',               # Healthcare providers, Biotech\n",
        "    'XLE': 'Energy',                   # Oil & Gas companies\n",
        "    'XLY': 'Consumer Discretionary',   # Retail, Automotive, Media\n",
        "    'XLP': 'Consumer Staples',         # Food & Beverage\n",
        "    'XLI': 'Industrials',              # Aerospace & Defense\n",
        "    'XLB': 'Materials',                # Chemicals, Mining\n",
        "    'XLU': 'Utilities',                # Electric & Gas utilities\n",
        "    'XLRE': 'Real Estate',             # REITs & Property management\n",
        "    'XLC': 'Communication Services'     # Telecom services & Media\n",
        "}\n",
        "\n",
        "# Mapping for standardizing sector names\n",
        "SECTOR_NAME_MAP = {\n",
        "    'Technology': 'Information Technology',\n",
        "    'Technology ': 'Information Technology',  # Handle trailing space\n",
        "    'Consumer_Discretionary': 'Consumer Discretionary',\n",
        "    'Consumer_Staples': 'Consumer Staples',\n",
        "    'Communication_Services': 'Communication Services',\n",
        "    'Real_Estate': 'Real Estate'\n",
        "}\n",
        "\n",
        "# Create reverse mapping for ETF lookup\n",
        "SECTOR_TO_ETF = {sector: etf for etf, sector in SECTOR_ETF_MAP.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility functions for data validation\n",
        "def validate_columns(df, required_cols, name):\n",
        "    \"\"\"Validate that all required columns are present.\"\"\"\n",
        "    missing_cols = set(required_cols) - set(df.columns)\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"{name}: Missing columns: {missing_cols}\")\n",
        "    return True\n",
        "\n",
        "def fix_price_relationships(df, name):\n",
        "    \"\"\"Fix price relationships in the data.\"\"\"\n",
        "    price_cols = ['Open', 'High', 'Low', 'Close']\n",
        "    \n",
        "    # Round to 4 decimal places to handle floating point precision\n",
        "    for col in price_cols:\n",
        "        df[col] = df[col].round(4)\n",
        "    \n",
        "    # Step 1: Basic price adjustments\n",
        "    df['High'] = df[price_cols].max(axis=1)\n",
        "    df['Low'] = df[price_cols].min(axis=1)\n",
        "    \n",
        "    # Step 2: Handle specific cases\n",
        "    # If Open/Close are outside High/Low range, adjust them\n",
        "    df.loc[df['Open'] > df['High'], 'Open'] = df['High']\n",
        "    df.loc[df['Open'] < df['Low'], 'Open'] = df['Low']\n",
        "    df.loc[df['Close'] > df['High'], 'Close'] = df['High']\n",
        "    df.loc[df['Close'] < df['Low'], 'Close'] = df['Low']\n",
        "    \n",
        "    # Step 3: Final validation with tolerance\n",
        "    tolerance = 0.0001  # 0.01% tolerance\n",
        "    invalid_price = (\n",
        "        (df['High'] * (1 - tolerance) < df['Low']) |\n",
        "        (df['High'] * (1 - tolerance) < df['Open']) |\n",
        "        (df['High'] * (1 - tolerance) < df['Close']) |\n",
        "        (df['Low'] * (1 + tolerance) > df['Open']) |\n",
        "        (df['Low'] * (1 + tolerance) > df['Close'])\n",
        "    )\n",
        "    \n",
        "    if invalid_price.any():\n",
        "        invalid_dates = df[invalid_price].index\n",
        "        logging.warning(f\"{name}: Found {len(invalid_dates)} invalid price relationships\")\n",
        "        \n",
        "        # Additional fixing attempt for remaining issues\n",
        "        problem_rows = df[invalid_price].copy()\n",
        "        problem_rows['High'] = problem_rows[price_cols].max(axis=1) * 1.0001\n",
        "        problem_rows['Low'] = problem_rows[price_cols].min(axis=1) * 0.9999\n",
        "        \n",
        "        # Update the original dataframe\n",
        "        df.loc[invalid_price] = problem_rows\n",
        "    \n",
        "    return df\n",
        "\n",
        "def validate_data_quality(df, name):\n",
        "    \"\"\"Validate data quality metrics.\"\"\"\n",
        "    # Make a copy to avoid modifying the original data\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Check date range\n",
        "    if len(df) < VALIDATION_CONFIG['min_trading_days']:\n",
        "        if name in ['GFS', 'RIVN']:  # Known newer stocks\n",
        "            logging.warning(f\"{name}: Newer stock with {len(df)} trading days\")\n",
        "            return df\n",
        "        raise ValueError(f\"{name}: Insufficient trading days ({len(df)})\")\n",
        "    \n",
        "    # Check missing data\n",
        "    missing_pct = (df.isnull().sum() / len(df) * 100).max()\n",
        "    if missing_pct > VALIDATION_CONFIG['max_missing_pct']:\n",
        "        raise ValueError(f\"{name}: High missing data ({missing_pct:.1f}%)\")\n",
        "    \n",
        "    # Check for invalid values\n",
        "    price_cols = ['Open', 'High', 'Low', 'Close']\n",
        "    for col in price_cols:\n",
        "        if (df[col] <= 0).any():\n",
        "            raise ValueError(f\"{name}: Invalid {col} values (<=0)\")\n",
        "        if df[col].isnull().any():\n",
        "            raise ValueError(f\"{name}: Missing {col} values\")\n",
        "    \n",
        "    if (df['Volume'] < 0).any():\n",
        "        raise ValueError(f\"{name}: Invalid Volume values (<0)\")\n",
        "    \n",
        "    # Fix price relationships\n",
        "    df = fix_price_relationships(df, name)\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main data loading functions\n",
        "def load_stock_data():\n",
        "    \"\"\"Load and validate stock data.\"\"\"\n",
        "    print(\"\\nLoading and validating stock data...\", flush=True)\n",
        "    stock_files = list(Path('../data/stocks').glob('*.csv'))\n",
        "    \n",
        "    stock_data = {}\n",
        "    validation_results = {'passed': [], 'failed': []}\n",
        "    \n",
        "    for file in tqdm(stock_files, desc=\"Loading stock data\"):\n",
        "        try:\n",
        "            # Load data\n",
        "            df = pd.read_csv(file)\n",
        "            name = file.stem\n",
        "            \n",
        "            # Convert date to datetime with UTC\n",
        "            df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
        "            \n",
        "            # Clean sector names\n",
        "            df['Sector'] = df['Sector'].str.strip()\n",
        "            df['Sector'] = df['Sector'].replace(SECTOR_NAME_MAP)\n",
        "            \n",
        "            # Add ticker column\n",
        "            df['Ticker'] = name\n",
        "            \n",
        "            # Sort by date\n",
        "            df = df.sort_values('Date')\n",
        "            \n",
        "            # Handle missing data\n",
        "            df = df.ffill(limit=5).bfill(limit=5)\n",
        "            \n",
        "            # Validate columns\n",
        "            validate_columns(df, REQUIRED_COLUMNS['stocks'], name)\n",
        "            \n",
        "            # Validate and fix data quality\n",
        "            df = validate_data_quality(df, name)\n",
        "            \n",
        "            # Store data\n",
        "            stock_data[name] = df\n",
        "            validation_results['passed'].append(name)\n",
        "            logging.info(f\"Validated {name} data: {len(df)} rows\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logging.warning(f\"{name}: {str(e)}\")\n",
        "            validation_results['failed'].append(name)\n",
        "            continue\n",
        "    \n",
        "    return stock_data, validation_results\n",
        "\n",
        "def load_sector_data():\n",
        "    \"\"\"Load and validate sector ETF data.\"\"\"\n",
        "    print(\"\\nLoading and validating sector data...\", flush=True)\n",
        "    sector_data = {}\n",
        "    validation_results = {'passed': [], 'failed': []}\n",
        "    \n",
        "    for etf, sector in SECTOR_ETF_MAP.items():\n",
        "        try:\n",
        "            # Load data\n",
        "            file_path = Path(f'../data/sectors/{etf}.csv')\n",
        "            if not file_path.exists():\n",
        "                raise FileNotFoundError(f\"No data file found for ETF {etf}\")\n",
        "            \n",
        "            df = pd.read_csv(file_path)\n",
        "            \n",
        "            # Convert date to datetime with UTC\n",
        "            df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
        "            \n",
        "            # Add sector information\n",
        "            df['Sector'] = sector\n",
        "            df['Ticker'] = etf\n",
        "            \n",
        "            # Sort by date\n",
        "            df = df.sort_values('Date')\n",
        "            \n",
        "            # Handle missing data\n",
        "            df = df.ffill(limit=5).bfill(limit=5)\n",
        "            \n",
        "            # Drop any remaining rows with missing values\n",
        "            df = df.dropna()\n",
        "            \n",
        "            # Validate columns\n",
        "            validate_columns(df, REQUIRED_COLUMNS['sectors'], f\"{sector} ({etf})\")\n",
        "            \n",
        "            # Validate and fix data quality\n",
        "            df = validate_data_quality(df, f\"{sector} ({etf})\")\n",
        "            \n",
        "            # Store data\n",
        "            sector_data[sector] = df\n",
        "            validation_results['passed'].append(sector)\n",
        "            logging.info(f\"Validated {sector} ({etf}) data: {len(df)} rows\")\n",
        "            \n",
        "            # Print summary\n",
        "            print(f\"\\n{etf} ({sector}) Summary:\", flush=True)\n",
        "            print(f\"- Date Range: {df['Date'].min():%Y-%m-%d} to {df['Date'].max():%Y-%m-%d}\")\n",
        "            print(f\"- Trading Days: {len(df)}\")\n",
        "            print(f\"- File: {file_path}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logging.warning(f\"{sector} ({etf}): {str(e)}\")\n",
        "            validation_results['failed'].append(sector)\n",
        "            \n",
        "            # Try to fix the data with more aggressive settings\n",
        "            try:\n",
        "                # Load data again\n",
        "                df = pd.read_csv(file_path)\n",
        "                \n",
        "                # Convert date to datetime with UTC\n",
        "                df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
        "                \n",
        "                # Add sector information\n",
        "                df['Sector'] = sector\n",
        "                df['Ticker'] = etf\n",
        "                \n",
        "                # Sort by date\n",
        "                df = df.sort_values('Date')\n",
        "                \n",
        "                # Handle missing data more aggressively\n",
        "                df = df.ffill(limit=10).bfill(limit=10)\n",
        "                \n",
        "                # Drop any remaining rows with missing values\n",
        "                df = df.dropna()\n",
        "                \n",
        "                # Validate columns\n",
        "                validate_columns(df, REQUIRED_COLUMNS['sectors'], f\"{sector} ({etf})\")\n",
        "                \n",
        "                # Validate and fix data quality with more aggressive settings\n",
        "                df = validate_data_quality(df, f\"{sector} ({etf})\")\n",
        "                \n",
        "                # Additional price relationship fixes if needed\n",
        "                df = fix_price_relationships(df, f\"{sector} ({etf})\")\n",
        "                \n",
        "                # If we get here, the retry was successful\n",
        "                sector_data[sector] = df\n",
        "                validation_results['passed'].append(sector)\n",
        "                validation_results['failed'].remove(sector)\n",
        "                logging.info(f\"Successfully fixed and validated {sector} ({etf}) data: {len(df)} rows\")\n",
        "                \n",
        "            except Exception as retry_e:\n",
        "                logging.error(f\"Failed to fix {sector} ({etf}) data: {str(retry_e)}\")\n",
        "                continue\n",
        "    \n",
        "    # Print sector coverage\n",
        "    print(\"\\nSector Coverage:\", flush=True)\n",
        "    print(f\"- Total Sectors: {len(SECTOR_ETF_MAP)}\")\n",
        "    print(f\"- Loaded Sectors: {len(validation_results['passed'])}\")\n",
        "    if validation_results['failed']:\n",
        "        print(f\"- Failed Sectors: {validation_results['failed']}\")\n",
        "    \n",
        "    return sector_data, validation_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation and merging functions\n",
        "def cross_validate_stock_sector(stock_df, sector_df, stock_name):\n",
        "    \"\"\"Cross-validate stock against its sector.\"\"\"\n",
        "    try:\n",
        "        # Get stock's sector\n",
        "        sector = stock_df['Sector'].iloc[0]\n",
        "        \n",
        "        # Ensure datetime index for both dataframes\n",
        "        stock_df = stock_df.set_index('Date')\n",
        "        sector_df = sector_df.set_index('Date')\n",
        "        \n",
        "        # Remove timezone info for alignment\n",
        "        stock_df.index = stock_df.index.tz_localize(None)\n",
        "        sector_df.index = sector_df.index.tz_localize(None)\n",
        "        \n",
        "        # Calculate returns\n",
        "        stock_returns = stock_df['Close'].pct_change().dropna()\n",
        "        sector_returns = sector_df['Close'].pct_change().dropna()\n",
        "        \n",
        "        # Align data\n",
        "        stock_returns, sector_returns = stock_returns.align(sector_returns, join='inner')\n",
        "        \n",
        "        if len(stock_returns) == 0:\n",
        "            raise ValueError(\"No overlapping data between stock and sector\")\n",
        "        \n",
        "        # Calculate correlation for different time windows\n",
        "        correlations = []\n",
        "        window_sizes = [30, 60, 90, 180, 360]  # Different window sizes in days\n",
        "        \n",
        "        for window in window_sizes:\n",
        "            if len(stock_returns) >= window:\n",
        "                rolling_corr = stock_returns.rolling(window=window).corr(sector_returns)\n",
        "                correlations.append(rolling_corr.mean())\n",
        "        \n",
        "        # Use the maximum correlation from different windows\n",
        "        max_correlation = max(correlations) if correlations else stock_returns.corr(sector_returns)\n",
        "        \n",
        "        # Define minimum correlation threshold based on data length\n",
        "        data_length = len(stock_returns)\n",
        "        \n",
        "        # Adjust correlation threshold based on data length\n",
        "        if data_length < 180:  # Less than 6 months of data\n",
        "            min_correlation = 0.2\n",
        "        elif data_length < 360:  # Less than 1 year of data\n",
        "            min_correlation = 0.25\n",
        "        elif data_length < 720:  # Less than 2 years of data\n",
        "            min_correlation = 0.28\n",
        "        else:\n",
        "            min_correlation = VALIDATION_CONFIG['min_stock_sector_corr']\n",
        "        \n",
        "        # Override for specific stocks if needed\n",
        "        NEWER_STOCKS = {\n",
        "            'MRNA': {'min_correlation': 0.2},\n",
        "            'ABNB': {'min_correlation': 0.2},\n",
        "            'CRWD': {'min_correlation': 0.2},\n",
        "            'DASH': {'min_correlation': 0.2},\n",
        "            'DDOG': {'min_correlation': 0.2},\n",
        "            'CVNA': {'min_correlation': 0.2},\n",
        "            'COIN': {'min_correlation': 0.2}\n",
        "        }\n",
        "        \n",
        "        min_correlation = min(\n",
        "            min_correlation,\n",
        "            NEWER_STOCKS.get(stock_name, {}).get('min_correlation', min_correlation)\n",
        "        )\n",
        "        \n",
        "        if max_correlation < min_correlation:\n",
        "            logging.warning(f\"{stock_name}: Low correlation with sector ({max_correlation:.3f} < {min_correlation})\")\n",
        "            # Don't fail validation, just warn\n",
        "            return True\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Cross-validation failed: {str(e)}\")\n",
        "\n",
        "def create_merged_dataset(stock_data, sector_data):\n",
        "    \"\"\"Create merged dataset with stock and sector data.\"\"\"\n",
        "    merged_data = []\n",
        "    \n",
        "    for ticker, stock_df in stock_data.items():\n",
        "        try:\n",
        "            # Get stock's sector\n",
        "            sector = stock_df['Sector'].iloc[0]\n",
        "            \n",
        "            # Get corresponding sector data\n",
        "            if sector not in sector_data:\n",
        "                raise ValueError(f\"No sector data found for {sector}\")\n",
        "            \n",
        "            sector_df = sector_data[sector]\n",
        "            \n",
        "            # Prepare data for merging\n",
        "            stock_df = stock_df.set_index('Date')\n",
        "            sector_df = sector_df.set_index('Date')\n",
        "            \n",
        "            # Remove timezone info for merging\n",
        "            stock_df.index = stock_df.index.tz_localize(None)\n",
        "            sector_df.index = sector_df.index.tz_localize(None)\n",
        "            \n",
        "            # Add sector data columns with prefix\n",
        "            for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
        "                stock_df[f'Sector_{col}'] = sector_df[col]\n",
        "            \n",
        "            # Reset index and add back Date column\n",
        "            stock_df = stock_df.reset_index()\n",
        "            \n",
        "            # Add to merged data\n",
        "            merged_data.append(stock_df)\n",
        "            \n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error merging {ticker}: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    if not merged_data:\n",
        "        raise ValueError(\"No data to merge\")\n",
        "    \n",
        "    # Combine all data\n",
        "    final_df = pd.concat(merged_data, ignore_index=True)\n",
        "    \n",
        "    # Sort by date and ticker\n",
        "    final_df = final_df.sort_values(['Date', 'Ticker'])\n",
        "    \n",
        "    return final_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting complete validation process...\n",
            "\n",
            "\n",
            "Loading and validating stock data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading stock data:   0%|          | 0/108 [00:00<?, ?it/s]2025-07-26 07:24:29,424 - WARNING - AAPL: Found 128 invalid price relationships\n",
            "2025-07-26 07:24:29,431 - INFO - Validated AAPL data: 2651 rows\n",
            "2025-07-26 07:24:29,465 - WARNING - ABNB: Found 60 invalid price relationships\n",
            "2025-07-26 07:24:29,470 - INFO - Validated ABNB data: 1155 rows\n",
            "2025-07-26 07:24:29,507 - WARNING - ADBE: Found 162 invalid price relationships\n",
            "2025-07-26 07:24:29,523 - INFO - Validated ADBE data: 2651 rows\n",
            "Loading stock data:   3%|▎         | 3/108 [00:00<00:04, 23.52it/s]2025-07-26 07:24:29,554 - WARNING - ADI: Found 200 invalid price relationships\n",
            "2025-07-26 07:24:29,560 - INFO - Validated ADI data: 2651 rows\n",
            "2025-07-26 07:24:29,583 - WARNING - ADP: Found 228 invalid price relationships\n",
            "2025-07-26 07:24:29,589 - INFO - Validated ADP data: 2651 rows\n",
            "2025-07-26 07:24:29,610 - WARNING - ADSK: Found 181 invalid price relationships\n",
            "2025-07-26 07:24:29,618 - INFO - Validated ADSK data: 2651 rows\n",
            "2025-07-26 07:24:29,640 - WARNING - AEP: Found 200 invalid price relationships\n",
            "2025-07-26 07:24:29,673 - INFO - Validated AEP data: 2651 rows\n",
            "Loading stock data:   6%|▋         | 7/108 [00:00<00:03, 25.59it/s]2025-07-26 07:24:29,736 - WARNING - ALGN: Found 220 invalid price relationships\n",
            "2025-07-26 07:24:29,748 - INFO - Validated ALGN data: 2651 rows\n",
            "2025-07-26 07:24:29,787 - WARNING - AMAT: Found 153 invalid price relationships\n",
            "2025-07-26 07:24:29,800 - INFO - Validated AMAT data: 2651 rows\n",
            "2025-07-26 07:24:29,833 - WARNING - AMD: Found 179 invalid price relationships\n",
            "2025-07-26 07:24:29,841 - INFO - Validated AMD data: 2651 rows\n",
            "Loading stock data:   9%|▉         | 10/108 [00:00<00:04, 21.80it/s]2025-07-26 07:24:29,867 - WARNING - AMGN: Found 172 invalid price relationships\n",
            "2025-07-26 07:24:29,873 - INFO - Validated AMGN data: 2651 rows\n",
            "2025-07-26 07:24:29,894 - WARNING - AMZN: Found 140 invalid price relationships\n",
            "2025-07-26 07:24:29,904 - INFO - Validated AMZN data: 2651 rows\n",
            "2025-07-26 07:24:29,930 - WARNING - ANSS: Found 330 invalid price relationships\n",
            "2025-07-26 07:24:29,935 - INFO - Validated ANSS data: 2650 rows\n",
            "2025-07-26 07:24:29,953 - WARNING - APD: Found 235 invalid price relationships\n",
            "2025-07-26 07:24:29,959 - INFO - Validated APD data: 2656 rows\n",
            "Loading stock data:  13%|█▎        | 14/108 [00:00<00:03, 25.90it/s]2025-07-26 07:24:29,979 - WARNING - ASML: Found 187 invalid price relationships\n",
            "2025-07-26 07:24:29,983 - INFO - Validated ASML data: 2651 rows\n",
            "2025-07-26 07:24:30,002 - WARNING - AVGO: Found 146 invalid price relationships\n",
            "2025-07-26 07:24:30,008 - INFO - Validated AVGO data: 2651 rows\n",
            "2025-07-26 07:24:30,035 - WARNING - BIIB: Found 201 invalid price relationships\n",
            "2025-07-26 07:24:30,041 - INFO - Validated BIIB data: 2651 rows\n",
            "2025-07-26 07:24:30,061 - WARNING - BKNG: Found 243 invalid price relationships\n",
            "2025-07-26 07:24:30,066 - INFO - Validated BKNG data: 2651 rows\n",
            "Loading stock data:  17%|█▋        | 18/108 [00:00<00:03, 29.31it/s]2025-07-26 07:24:30,086 - WARNING - BKR: Found 181 invalid price relationships\n",
            "2025-07-26 07:24:30,093 - INFO - Validated BKR data: 2651 rows\n",
            "2025-07-26 07:24:30,125 - WARNING - CDNS: Found 242 invalid price relationships\n",
            "2025-07-26 07:24:30,141 - INFO - Validated CDNS data: 2651 rows\n",
            "2025-07-26 07:24:30,191 - WARNING - CHTR: Found 255 invalid price relationships\n",
            "2025-07-26 07:24:30,200 - INFO - Validated CHTR data: 2651 rows\n",
            "2025-07-26 07:24:30,248 - WARNING - CMCSA: Found 180 invalid price relationships\n",
            "2025-07-26 07:24:30,264 - INFO - Validated CMCSA data: 2651 rows\n",
            "Loading stock data:  20%|██        | 22/108 [00:00<00:03, 25.21it/s]2025-07-26 07:24:30,303 - WARNING - COIN: Found 23 invalid price relationships\n",
            "2025-07-26 07:24:30,315 - INFO - Validated COIN data: 1076 rows\n",
            "2025-07-26 07:24:30,351 - WARNING - COST: Found 179 invalid price relationships\n",
            "2025-07-26 07:24:30,356 - INFO - Validated COST data: 2651 rows\n",
            "2025-07-26 07:24:30,384 - WARNING - CPRT: Found 228 invalid price relationships\n",
            "2025-07-26 07:24:30,393 - INFO - Validated CPRT data: 2651 rows\n",
            "Loading stock data:  23%|██▎       | 25/108 [00:00<00:03, 24.55it/s]2025-07-26 07:24:30,444 - WARNING - CRWD: Found 75 invalid price relationships\n",
            "2025-07-26 07:24:30,456 - INFO - Validated CRWD data: 1534 rows\n",
            "2025-07-26 07:24:30,488 - WARNING - CSCO: Found 167 invalid price relationships\n",
            "2025-07-26 07:24:30,496 - INFO - Validated CSCO data: 2651 rows\n",
            "2025-07-26 07:24:30,520 - WARNING - CSGP: Found 303 invalid price relationships\n",
            "2025-07-26 07:24:30,526 - INFO - Validated CSGP data: 2656 rows\n",
            "Loading stock data:  26%|██▌       | 28/108 [00:01<00:03, 24.09it/s]2025-07-26 07:24:30,567 - WARNING - CSX: Found 192 invalid price relationships\n",
            "2025-07-26 07:24:30,579 - INFO - Validated CSX data: 2651 rows\n",
            "2025-07-26 07:24:30,607 - WARNING - CTAS: Found 283 invalid price relationships\n",
            "2025-07-26 07:24:30,614 - INFO - Validated CTAS data: 2651 rows\n",
            "2025-07-26 07:24:30,634 - WARNING - CTSH: Found 209 invalid price relationships\n",
            "2025-07-26 07:24:30,648 - INFO - Validated CTSH data: 2651 rows\n",
            "Loading stock data:  29%|██▊       | 31/108 [00:01<00:03, 24.25it/s]2025-07-26 07:24:30,682 - WARNING - CVNA: Found 152 invalid price relationships\n",
            "2025-07-26 07:24:30,687 - INFO - Validated CVNA data: 2067 rows\n",
            "2025-07-26 07:24:30,703 - WARNING - DASH: Found 58 invalid price relationships\n",
            "2025-07-26 07:24:30,710 - INFO - Validated DASH data: 1156 rows\n",
            "2025-07-26 07:24:30,726 - WARNING - DDOG: Found 59 invalid price relationships\n",
            "2025-07-26 07:24:30,732 - INFO - Validated DDOG data: 1465 rows\n",
            "2025-07-26 07:24:30,754 - WARNING - DLTR: Found 203 invalid price relationships\n",
            "2025-07-26 07:24:30,762 - INFO - Validated DLTR data: 2651 rows\n",
            "Loading stock data:  32%|███▏      | 35/108 [00:01<00:02, 27.22it/s]2025-07-26 07:24:30,784 - WARNING - DOCU: Found 81 invalid price relationships\n",
            "2025-07-26 07:24:30,789 - INFO - Validated DOCU data: 1816 rows\n",
            "2025-07-26 07:24:30,811 - WARNING - DXCM: Found 214 invalid price relationships\n",
            "2025-07-26 07:24:30,816 - INFO - Validated DXCM data: 2651 rows\n",
            "2025-07-26 07:24:30,837 - WARNING - EA: Found 180 invalid price relationships\n",
            "2025-07-26 07:24:30,842 - INFO - Validated EA data: 2651 rows\n",
            "2025-07-26 07:24:30,864 - WARNING - EBAY: Found 187 invalid price relationships\n",
            "2025-07-26 07:24:30,870 - INFO - Validated EBAY data: 2651 rows\n",
            "Loading stock data:  36%|███▌      | 39/108 [00:01<00:02, 29.95it/s]2025-07-26 07:24:30,896 - WARNING - ENPH: Found 320 invalid price relationships\n",
            "2025-07-26 07:24:30,902 - INFO - Validated ENPH data: 2651 rows\n",
            "2025-07-26 07:24:30,921 - WARNING - EQIX: Found 322 invalid price relationships\n",
            "2025-07-26 07:24:30,927 - INFO - Validated EQIX data: 2656 rows\n",
            "2025-07-26 07:24:30,948 - WARNING - EXC: Found 182 invalid price relationships\n",
            "2025-07-26 07:24:30,954 - INFO - Validated EXC data: 2651 rows\n",
            "2025-07-26 07:24:30,978 - WARNING - FANG: Found 171 invalid price relationships\n",
            "2025-07-26 07:24:30,985 - INFO - Validated FANG data: 2651 rows\n",
            "Loading stock data:  40%|███▉      | 43/108 [00:01<00:02, 31.24it/s]2025-07-26 07:24:31,011 - WARNING - FAST: Found 196 invalid price relationships\n",
            "2025-07-26 07:24:31,017 - INFO - Validated FAST data: 2651 rows\n",
            "2025-07-26 07:24:31,037 - WARNING - FCX: Found 194 invalid price relationships\n",
            "2025-07-26 07:24:31,045 - INFO - Validated FCX data: 2656 rows\n",
            "2025-07-26 07:24:31,073 - WARNING - FTNT: Found 183 invalid price relationships\n",
            "2025-07-26 07:24:31,078 - INFO - Validated FTNT data: 2651 rows\n",
            "2025-07-26 07:24:31,088 - WARNING - GFS: Newer stock with 938 trading days\n",
            "2025-07-26 07:24:31,090 - INFO - Validated GFS data: 938 rows\n",
            "Loading stock data:  44%|████▎     | 47/108 [00:01<00:01, 33.26it/s]2025-07-26 07:24:31,113 - WARNING - GILD: Found 124 invalid price relationships\n",
            "2025-07-26 07:24:31,119 - INFO - Validated GILD data: 2651 rows\n",
            "2025-07-26 07:24:31,138 - WARNING - GOOG: Found 186 invalid price relationships\n",
            "2025-07-26 07:24:31,147 - INFO - Validated GOOG data: 2651 rows\n",
            "2025-07-26 07:24:31,176 - WARNING - GOOGL: Found 149 invalid price relationships\n",
            "2025-07-26 07:24:31,186 - INFO - Validated GOOGL data: 2651 rows\n",
            "2025-07-26 07:24:31,219 - WARNING - HON: Found 239 invalid price relationships\n",
            "2025-07-26 07:24:31,234 - INFO - Validated HON data: 2651 rows\n",
            "Loading stock data:  47%|████▋     | 51/108 [00:01<00:01, 31.23it/s]2025-07-26 07:24:31,261 - WARNING - IDXX: Found 288 invalid price relationships\n",
            "2025-07-26 07:24:31,268 - INFO - Validated IDXX data: 2651 rows\n",
            "2025-07-26 07:24:31,291 - WARNING - ILMN: Found 201 invalid price relationships\n",
            "2025-07-26 07:24:31,297 - INFO - Validated ILMN data: 2651 rows\n",
            "2025-07-26 07:24:31,317 - WARNING - INTC: Found 155 invalid price relationships\n",
            "2025-07-26 07:24:31,327 - INFO - Validated INTC data: 2651 rows\n",
            "2025-07-26 07:24:31,348 - WARNING - INTU: Found 224 invalid price relationships\n",
            "2025-07-26 07:24:31,353 - INFO - Validated INTU data: 2651 rows\n",
            "Loading stock data:  51%|█████     | 55/108 [00:01<00:01, 31.92it/s]2025-07-26 07:24:31,376 - WARNING - ISRG: Found 236 invalid price relationships\n",
            "2025-07-26 07:24:31,383 - INFO - Validated ISRG data: 2651 rows\n",
            "2025-07-26 07:24:31,448 - WARNING - KDP: Found 273 invalid price relationships\n",
            "2025-07-26 07:24:31,461 - INFO - Validated KDP data: 2651 rows\n",
            "2025-07-26 07:24:31,500 - WARNING - KHC: Found 148 invalid price relationships\n",
            "2025-07-26 07:24:31,508 - INFO - Validated KHC data: 2525 rows\n",
            "2025-07-26 07:24:31,536 - WARNING - KLAC: Found 241 invalid price relationships\n",
            "2025-07-26 07:24:31,546 - INFO - Validated KLAC data: 2651 rows\n",
            "Loading stock data:  55%|█████▍    | 59/108 [00:02<00:01, 27.34it/s]2025-07-26 07:24:31,567 - WARNING - LCID: Found 133 invalid price relationships\n",
            "2025-07-26 07:24:31,572 - INFO - Validated LCID data: 1218 rows\n",
            "2025-07-26 07:24:31,595 - WARNING - LIN: Found 209 invalid price relationships\n",
            "2025-07-26 07:24:31,602 - INFO - Validated LIN data: 2656 rows\n",
            "2025-07-26 07:24:31,622 - WARNING - LRCX: Found 160 invalid price relationships\n",
            "2025-07-26 07:24:31,629 - INFO - Validated LRCX data: 2651 rows\n",
            "2025-07-26 07:24:31,677 - WARNING - MAR: Found 203 invalid price relationships\n",
            "2025-07-26 07:24:31,692 - INFO - Validated MAR data: 2651 rows\n",
            "Loading stock data:  58%|█████▊    | 63/108 [00:02<00:01, 27.42it/s]2025-07-26 07:24:31,717 - WARNING - MCHP: Found 170 invalid price relationships\n",
            "2025-07-26 07:24:31,722 - INFO - Validated MCHP data: 2651 rows\n",
            "2025-07-26 07:24:31,744 - WARNING - MDLZ: Found 198 invalid price relationships\n",
            "2025-07-26 07:24:31,751 - INFO - Validated MDLZ data: 2651 rows\n",
            "2025-07-26 07:24:31,771 - WARNING - MELI: Found 272 invalid price relationships\n",
            "2025-07-26 07:24:31,778 - INFO - Validated MELI data: 2651 rows\n",
            "2025-07-26 07:24:31,802 - WARNING - META: Found 110 invalid price relationships\n",
            "2025-07-26 07:24:31,810 - INFO - Validated META data: 2651 rows\n",
            "Loading stock data:  62%|██████▏   | 67/108 [00:02<00:01, 29.10it/s]2025-07-26 07:24:31,836 - WARNING - MNST: Found 217 invalid price relationships\n",
            "2025-07-26 07:24:31,845 - INFO - Validated MNST data: 2651 rows\n",
            "2025-07-26 07:24:31,863 - WARNING - MRNA: Found 85 invalid price relationships\n",
            "2025-07-26 07:24:31,867 - INFO - Validated MRNA data: 1661 rows\n",
            "2025-07-26 07:24:31,887 - WARNING - MRVL: Found 189 invalid price relationships\n",
            "2025-07-26 07:24:31,893 - INFO - Validated MRVL data: 2651 rows\n",
            "2025-07-26 07:24:31,911 - WARNING - MSFT: Found 134 invalid price relationships\n",
            "2025-07-26 07:24:31,916 - INFO - Validated MSFT data: 2651 rows\n",
            "Loading stock data:  66%|██████▌   | 71/108 [00:02<00:01, 31.26it/s]2025-07-26 07:24:31,936 - WARNING - MTCH: Found 195 invalid price relationships\n",
            "2025-07-26 07:24:31,942 - INFO - Validated MTCH data: 2651 rows\n",
            "2025-07-26 07:24:31,964 - WARNING - MU: Found 102 invalid price relationships\n",
            "2025-07-26 07:24:31,969 - INFO - Validated MU data: 2651 rows\n",
            "2025-07-26 07:24:31,998 - WARNING - NFLX: Found 118 invalid price relationships\n",
            "2025-07-26 07:24:32,003 - INFO - Validated NFLX data: 2651 rows\n",
            "2025-07-26 07:24:32,028 - WARNING - NVDA: Found 86 invalid price relationships\n",
            "2025-07-26 07:24:32,033 - INFO - Validated NVDA data: 2651 rows\n",
            "Loading stock data:  69%|██████▉   | 75/108 [00:02<00:01, 32.17it/s]2025-07-26 07:24:32,056 - WARNING - NXPI: Found 236 invalid price relationships\n",
            "2025-07-26 07:24:32,063 - INFO - Validated NXPI data: 2651 rows\n",
            "2025-07-26 07:24:32,091 - WARNING - ODFL: Found 280 invalid price relationships\n",
            "2025-07-26 07:24:32,098 - INFO - Validated ODFL data: 2651 rows\n",
            "2025-07-26 07:24:32,117 - WARNING - OKTA: Found 112 invalid price relationships\n",
            "2025-07-26 07:24:32,124 - INFO - Validated OKTA data: 2081 rows\n",
            "2025-07-26 07:24:32,146 - WARNING - ON: Found 215 invalid price relationships\n",
            "2025-07-26 07:24:32,152 - INFO - Validated ON data: 2656 rows\n",
            "Loading stock data:  73%|███████▎  | 79/108 [00:02<00:00, 32.51it/s]2025-07-26 07:24:32,179 - WARNING - ORLY: Found 283 invalid price relationships\n",
            "2025-07-26 07:24:32,184 - INFO - Validated ORLY data: 2651 rows\n",
            "2025-07-26 07:24:32,203 - WARNING - PANW: Found 179 invalid price relationships\n",
            "2025-07-26 07:24:32,212 - INFO - Validated PANW data: 2651 rows\n",
            "2025-07-26 07:24:32,233 - WARNING - PAYX: Found 237 invalid price relationships\n",
            "2025-07-26 07:24:32,238 - INFO - Validated PAYX data: 2651 rows\n",
            "2025-07-26 07:24:32,260 - WARNING - PCAR: Found 189 invalid price relationships\n",
            "2025-07-26 07:24:32,271 - INFO - Validated PCAR data: 2651 rows\n",
            "Loading stock data:  77%|███████▋  | 83/108 [00:02<00:00, 32.83it/s]2025-07-26 07:24:32,300 - WARNING - PEP: Found 188 invalid price relationships\n",
            "2025-07-26 07:24:32,307 - INFO - Validated PEP data: 2651 rows\n",
            "2025-07-26 07:24:32,334 - WARNING - PLD: Found 224 invalid price relationships\n",
            "2025-07-26 07:24:32,344 - INFO - Validated PLD data: 2656 rows\n",
            "2025-07-26 07:24:32,366 - WARNING - PYPL: Found 112 invalid price relationships\n",
            "2025-07-26 07:24:32,371 - INFO - Validated PYPL data: 2525 rows\n",
            "2025-07-26 07:24:32,397 - WARNING - QCOM: Found 138 invalid price relationships\n",
            "2025-07-26 07:24:32,402 - INFO - Validated QCOM data: 2651 rows\n",
            "Loading stock data:  81%|████████  | 87/108 [00:03<00:00, 32.18it/s]2025-07-26 07:24:32,415 - WARNING - RBLX: Found 68 invalid price relationships\n",
            "2025-07-26 07:24:32,422 - INFO - Validated RBLX data: 1095 rows\n",
            "2025-07-26 07:24:32,447 - WARNING - REGN: Found 243 invalid price relationships\n",
            "2025-07-26 07:24:32,455 - INFO - Validated REGN data: 2651 rows\n",
            "2025-07-26 07:24:32,464 - WARNING - RIVN: Newer stock with 929 trading days\n",
            "2025-07-26 07:24:32,467 - INFO - Validated RIVN data: 929 rows\n",
            "2025-07-26 07:24:32,488 - WARNING - ROKU: Found 51 invalid price relationships\n",
            "2025-07-26 07:24:32,494 - INFO - Validated ROKU data: 1961 rows\n",
            "2025-07-26 07:24:32,520 - WARNING - ROST: Found 218 invalid price relationships\n",
            "2025-07-26 07:24:32,527 - INFO - Validated ROST data: 2651 rows\n",
            "Loading stock data:  85%|████████▌ | 92/108 [00:03<00:00, 34.46it/s]2025-07-26 07:24:32,563 - WARNING - SBUX: Found 155 invalid price relationships\n",
            "2025-07-26 07:24:32,569 - INFO - Validated SBUX data: 2651 rows\n",
            "2025-07-26 07:24:32,594 - WARNING - SIRI: Found 527 invalid price relationships\n",
            "2025-07-26 07:24:32,602 - INFO - Validated SIRI data: 2651 rows\n",
            "2025-07-26 07:24:32,622 - WARNING - SNAP: Found 123 invalid price relationships\n",
            "2025-07-26 07:24:32,628 - INFO - Validated SNAP data: 2107 rows\n",
            "2025-07-26 07:24:32,663 - WARNING - SNPS: Found 246 invalid price relationships\n",
            "2025-07-26 07:24:32,672 - INFO - Validated SNPS data: 2651 rows\n",
            "Loading stock data:  89%|████████▉ | 96/108 [00:03<00:00, 32.10it/s]2025-07-26 07:24:32,701 - WARNING - TEAM: Found 216 invalid price relationships\n",
            "2025-07-26 07:24:32,707 - INFO - Validated TEAM data: 2415 rows\n",
            "2025-07-26 07:24:32,728 - WARNING - TMUS: Found 181 invalid price relationships\n",
            "2025-07-26 07:24:32,734 - INFO - Validated TMUS data: 2651 rows\n",
            "2025-07-26 07:24:32,762 - WARNING - TSLA: Found 53 invalid price relationships\n",
            "2025-07-26 07:24:32,769 - INFO - Validated TSLA data: 2651 rows\n",
            "2025-07-26 07:24:32,790 - WARNING - TTD: Found 120 invalid price relationships\n",
            "2025-07-26 07:24:32,796 - INFO - Validated TTD data: 2218 rows\n",
            "Loading stock data:  93%|█████████▎| 100/108 [00:03<00:00, 32.22it/s]2025-07-26 07:24:32,820 - WARNING - TXN: Found 178 invalid price relationships\n",
            "2025-07-26 07:24:32,826 - INFO - Validated TXN data: 2651 rows\n",
            "2025-07-26 07:24:32,846 - WARNING - VRSK: Found 278 invalid price relationships\n",
            "2025-07-26 07:24:32,852 - INFO - Validated VRSK data: 2651 rows\n",
            "2025-07-26 07:24:32,876 - WARNING - VRTX: Found 186 invalid price relationships\n",
            "2025-07-26 07:24:32,887 - INFO - Validated VRTX data: 2651 rows\n",
            "2025-07-26 07:24:32,907 - WARNING - WBD: Found 204 invalid price relationships\n",
            "2025-07-26 07:24:32,912 - INFO - Validated WBD data: 2651 rows\n",
            "Loading stock data:  96%|█████████▋| 104/108 [00:03<00:00, 32.85it/s]2025-07-26 07:24:32,937 - WARNING - WDAY: Found 172 invalid price relationships\n",
            "2025-07-26 07:24:32,945 - INFO - Validated WDAY data: 2651 rows\n",
            "2025-07-26 07:24:32,970 - WARNING - XEL: Found 224 invalid price relationships\n",
            "2025-07-26 07:24:32,984 - INFO - Validated XEL data: 2651 rows\n",
            "2025-07-26 07:24:33,018 - WARNING - ZM: Found 61 invalid price relationships\n",
            "2025-07-26 07:24:33,037 - INFO - Validated ZM data: 1571 rows\n",
            "2025-07-26 07:24:33,076 - WARNING - ZS: Found 128 invalid price relationships\n",
            "2025-07-26 07:24:33,095 - INFO - Validated ZS data: 1845 rows\n",
            "Loading stock data: 100%|██████████| 108/108 [00:03<00:00, 29.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sector Distribution in Stock Data:\n",
            "- Communication Services: 6 stocks - ['CHTR', 'CMCSA', 'NFLX', 'SIRI', 'TMUS', 'WBD']\n",
            "- Consumer Discretionary: 14 stocks - ['ABNB', 'AMZN', 'BKNG', 'CVNA', 'DLTR', 'EBAY', 'LCID', 'MAR', 'MELI', 'ORLY', 'RIVN', 'ROST', 'SBUX', 'TSLA']\n",
            "- Consumer Staples: 6 stocks - ['COST', 'KDP', 'KHC', 'MDLZ', 'MNST', 'PEP']\n",
            "- Energy: 2 stocks - ['BKR', 'FANG']\n",
            "- Financials: 2 stocks - ['COIN', 'PYPL']\n",
            "- Healthcare: 11 stocks - ['ALGN', 'AMGN', 'BIIB', 'DXCM', 'GILD', 'IDXX', 'ILMN', 'ISRG', 'MRNA', 'REGN', 'VRTX']\n",
            "- Industrials: 7 stocks - ['CPRT', 'CSX', 'CTAS', 'FAST', 'HON', 'ODFL', 'PCAR']\n",
            "- Information Technology: 51 stocks - ['AAPL', 'ADBE', 'ADI', 'ADP', 'ADSK', 'AMAT', 'AMD', 'ANSS', 'ASML', 'AVGO', 'CDNS', 'CRWD', 'CSCO', 'CTSH', 'DASH', 'DDOG', 'DOCU', 'EA', 'ENPH', 'FTNT', 'GFS', 'GOOG', 'GOOGL', 'INTC', 'INTU', 'KLAC', 'LRCX', 'MCHP', 'META', 'MRVL', 'MSFT', 'MTCH', 'MU', 'NVDA', 'NXPI', 'OKTA', 'ON', 'PANW', 'PAYX', 'QCOM', 'RBLX', 'ROKU', 'SNAP', 'SNPS', 'TEAM', 'TTD', 'TXN', 'VRSK', 'WDAY', 'ZM', 'ZS']\n",
            "- Materials: 3 stocks - ['APD', 'FCX', 'LIN']\n",
            "- Real Estate: 3 stocks - ['CSGP', 'EQIX', 'PLD']\n",
            "- Utilities: 3 stocks - ['AEP', 'EXC', 'XEL']\n",
            "\n",
            "Loading and validating sector data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "2025-07-26 07:24:33,165 - WARNING - Information Technology (XLK): Found 233 invalid price relationships\n",
            "2025-07-26 07:24:33,172 - INFO - Validated Information Technology (XLK) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XLK (Information Technology) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,202 - WARNING - Financials (XLF): Found 282 invalid price relationships\n",
            "2025-07-26 07:24:33,208 - INFO - Validated Financials (XLF) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLK.csv\n",
            "\n",
            "XLF (Financials) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,259 - WARNING - Healthcare (XLV): Found 228 invalid price relationships\n",
            "2025-07-26 07:24:33,265 - INFO - Validated Healthcare (XLV) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLF.csv\n",
            "\n",
            "XLV (Healthcare) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,297 - WARNING - Energy (XLE): Found 138 invalid price relationships\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLV.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,307 - INFO - Validated Energy (XLE) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XLE (Energy) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,345 - WARNING - Consumer Discretionary (XLY): Found 273 invalid price relationships\n",
            "2025-07-26 07:24:33,350 - INFO - Validated Consumer Discretionary (XLY) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLE.csv\n",
            "\n",
            "XLY (Consumer Discretionary) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,381 - WARNING - Consumer Staples (XLP): Found 303 invalid price relationships\n",
            "2025-07-26 07:24:33,387 - INFO - Validated Consumer Staples (XLP) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLY.csv\n",
            "\n",
            "XLP (Consumer Staples) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,415 - WARNING - Industrials (XLI): Found 254 invalid price relationships\n",
            "2025-07-26 07:24:33,423 - INFO - Validated Industrials (XLI) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLP.csv\n",
            "\n",
            "XLI (Industrials) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,462 - WARNING - Materials (XLB): Found 294 invalid price relationships\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,468 - INFO - Validated Materials (XLB) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XLB (Materials) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,499 - WARNING - Utilities (XLU): Found 215 invalid price relationships\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLB.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,508 - INFO - Validated Utilities (XLU) data: 2656 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XLU (Utilities) Summary:\n",
            "- Date Range: 2015-01-02 to 2025-07-25\n",
            "- Trading Days: 2656\n",
            "- File: ..\\data\\sectors\\XLU.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,545 - WARNING - Real Estate (XLRE): Found 442 invalid price relationships\n",
            "2025-07-26 07:24:33,550 - INFO - Validated Real Estate (XLRE) data: 2463 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XLRE (Real Estate) Summary:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,589 - WARNING - Communication Services (XLC): Found 195 invalid price relationships\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Date Range: 2015-10-08 to 2025-07-25\n",
            "- Trading Days: 2463\n",
            "- File: ..\\data\\sectors\\XLRE.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-26 07:24:33,603 - INFO - Validated Communication Services (XLC) data: 1785 rows\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XLC (Communication Services) Summary:\n",
            "- Date Range: 2018-06-19 to 2025-07-25\n",
            "- Trading Days: 1785\n",
            "- File: ..\\data\\sectors\\XLC.csv\n",
            "\n",
            "Sector Coverage:\n",
            "- Total Sectors: 11\n",
            "- Loaded Sectors: 11\n",
            "\n",
            "Performing cross-validation...\n",
            "Available sectors: ['Information Technology', 'Financials', 'Healthcare', 'Energy', 'Consumer Discretionary', 'Consumer Staples', 'Industrials', 'Materials', 'Utilities', 'Real Estate', 'Communication Services']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-validating stocks: 100%|██████████| 108/108 [00:00<00:00, 155.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-validation Summary:\n",
            "Total stocks processed: 108\n",
            "Passed: 108\n",
            "Failed: 0\n",
            "\n",
            "Creating merged dataset...\n",
            "\n",
            "Merged data saved:\n",
            "- Total rows: 266029\n",
            "- Unique stocks: 108\n",
            "- Date range: 2015-01-02 to 2025-07-25\n",
            "\n",
            "Sector distribution in final dataset:\n",
            "- Information Technology: 51 stocks - ['AAPL', 'ADBE', 'ADI', 'ADP', 'ADSK', 'AMAT', 'AMD', 'ANSS', 'ASML', 'AVGO', 'CDNS', 'CRWD', 'CSCO', 'CTSH', 'DASH', 'DDOG', 'DOCU', 'EA', 'ENPH', 'FTNT', 'GFS', 'GOOG', 'GOOGL', 'INTC', 'INTU', 'KLAC', 'LRCX', 'MCHP', 'META', 'MRVL', 'MSFT', 'MTCH', 'MU', 'NVDA', 'NXPI', 'OKTA', 'ON', 'PANW', 'PAYX', 'QCOM', 'RBLX', 'ROKU', 'SNAP', 'SNPS', 'TEAM', 'TTD', 'TXN', 'VRSK', 'WDAY', 'ZM', 'ZS']\n",
            "- Consumer Discretionary: 14 stocks - ['ABNB', 'AMZN', 'BKNG', 'CVNA', 'DLTR', 'EBAY', 'LCID', 'MAR', 'MELI', 'ORLY', 'RIVN', 'ROST', 'SBUX', 'TSLA']\n",
            "- Healthcare: 11 stocks - ['ALGN', 'AMGN', 'BIIB', 'DXCM', 'GILD', 'IDXX', 'ILMN', 'ISRG', 'MRNA', 'REGN', 'VRTX']\n",
            "- Industrials: 7 stocks - ['CPRT', 'CSX', 'CTAS', 'FAST', 'HON', 'ODFL', 'PCAR']\n",
            "- Communication Services: 6 stocks - ['CHTR', 'CMCSA', 'NFLX', 'SIRI', 'TMUS', 'WBD']\n",
            "- Consumer Staples: 6 stocks - ['COST', 'KDP', 'KHC', 'MDLZ', 'MNST', 'PEP']\n",
            "- Materials: 3 stocks - ['APD', 'FCX', 'LIN']\n",
            "- Real Estate: 3 stocks - ['CSGP', 'EQIX', 'PLD']\n",
            "- Utilities: 3 stocks - ['AEP', 'EXC', 'XEL']\n",
            "- Energy: 2 stocks - ['BKR', 'FANG']\n",
            "- Financials: 2 stocks - ['COIN', 'PYPL']\n",
            "\n",
            "Validation process complete!\n"
          ]
        }
      ],
      "source": [
        "# Main execution\n",
        "print(\"Starting complete validation process...\\n\")\n",
        "\n",
        "# Load and validate stock data\n",
        "stock_data, stock_validation = load_stock_data()\n",
        "\n",
        "# Print sector distribution in stock data\n",
        "if stock_data:\n",
        "    print(\"\\nSector Distribution in Stock Data:\")\n",
        "    sector_counts = {}\n",
        "    for ticker, df in stock_data.items():\n",
        "        sector = df['Sector'].iloc[0]\n",
        "        if sector not in sector_counts:\n",
        "            sector_counts[sector] = []\n",
        "        sector_counts[sector].append(ticker)\n",
        "    \n",
        "    for sector in sorted(sector_counts.keys()):\n",
        "        print(f\"- {sector}: {len(sector_counts[sector])} stocks - {sorted(sector_counts[sector])}\")\n",
        "    \n",
        "    # Check for missing sectors\n",
        "    all_sectors = set(SECTOR_ETF_MAP.values())\n",
        "    found_sectors = set(sector_counts.keys())\n",
        "    missing_sectors = all_sectors - found_sectors\n",
        "    if missing_sectors:\n",
        "        print(f\"\\nMissing sectors in stock data: {missing_sectors}\")\n",
        "\n",
        "# Load and validate sector data\n",
        "sector_data, sector_validation = load_sector_data()\n",
        "\n",
        "# Perform cross-validation if both validations passed\n",
        "if stock_data and sector_data:\n",
        "    print(\"\\nPerforming cross-validation...\")\n",
        "    print(\"Available sectors:\", list(sector_data.keys()), flush=True)\n",
        "    \n",
        "    validation_results = {'passed': [], 'failed': [], 'reasons': {}}\n",
        "    \n",
        "    for stock_name, stock_df in tqdm(stock_data.items(), desc=\"Cross-validating stocks\"):\n",
        "        sector = stock_df['Sector'].iloc[0]\n",
        "        \n",
        "        if sector not in sector_data:\n",
        "            validation_results['failed'].append(stock_name)\n",
        "            validation_results['reasons'][stock_name] = 'sector_not_found'\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            cross_validate_stock_sector(stock_df, sector_data[sector], stock_name)\n",
        "            validation_results['passed'].append(stock_name)\n",
        "        except Exception as e:\n",
        "            validation_results['failed'].append(stock_name)\n",
        "            validation_results['reasons'][stock_name] = str(e)\n",
        "    \n",
        "    # Print cross-validation summary\n",
        "    print(\"\\nCross-validation Summary:\")\n",
        "    print(f\"Total stocks processed: {len(stock_data)}\")\n",
        "    print(f\"Passed: {len(validation_results['passed'])}\")\n",
        "    print(f\"Failed: {len(validation_results['failed'])}\")\n",
        "    \n",
        "    if validation_results['failed']:\n",
        "        print(\"\\nFailed validations by reason:\")\n",
        "        reason_counts = {}\n",
        "        for stock in validation_results['failed']:\n",
        "            reason = validation_results['reasons'][stock]\n",
        "            if reason not in reason_counts:\n",
        "                reason_counts[reason] = []\n",
        "            reason_counts[reason].append(stock)\n",
        "        \n",
        "        for reason, stocks in reason_counts.items():\n",
        "            print(f\"- {reason}: {len(stocks)} stocks - {sorted(stocks)}\")\n",
        "    \n",
        "    # Create merged dataset if validation passed\n",
        "    if validation_results['passed']:\n",
        "        try:\n",
        "            print(\"\\nCreating merged dataset...\")\n",
        "            merged_df = create_merged_dataset(stock_data, sector_data)\n",
        "            \n",
        "            # Create output directories\n",
        "            for dir_path in ['../data/processed', '../data/enriched']:\n",
        "                Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
        "            \n",
        "            # Save merged data to both locations for backward compatibility\n",
        "            merged_df.to_csv('../data/processed/merged_data.csv', index=False)\n",
        "            merged_df.to_csv('../data/enriched/nasdaq_validated.csv', index=False)\n",
        "            \n",
        "            print(f\"\\nMerged data saved:\")\n",
        "            print(f\"- Total rows: {len(merged_df)}\")\n",
        "            print(f\"- Unique stocks: {merged_df['Ticker'].nunique()}\")\n",
        "            print(f\"- Date range: {merged_df['Date'].min():%Y-%m-%d} to {merged_df['Date'].max():%Y-%m-%d}\")\n",
        "            \n",
        "            # Print sector distribution in final dataset\n",
        "            print(\"\\nSector distribution in final dataset:\")\n",
        "            sector_counts = merged_df.groupby('Sector')['Ticker'].nunique().sort_values(ascending=False)\n",
        "            for sector, count in sector_counts.items():\n",
        "                tickers = sorted(merged_df[merged_df['Sector'] == sector]['Ticker'].unique())\n",
        "                print(f\"- {sector}: {count} stocks - {tickers}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\nError creating merged dataset: {str(e)}\")\n",
        "\n",
        "print(\"\\nValidation process complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
